/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as EdenAi from "../../../..";
export interface AudiotextToSpeechTextToSpeechRequest {
    /** It can be one (ex: **'amazon'** or **'google'**) or multiple provider(s) (ex: **'amazon,microsoft,google'**)             that the data will be redirected to in order to get the processed results. <span style="white-space: nowrap">`non-empty`</span> */
    providers: string;
    /**
     * Providers in this list will be used as fallback if the call to provider in `providers` parameter fails.
     *     To use this feature, you must input **only one** provider in the `providers` parameter. but you can put up to 5 fallbacks.
     *
     * They will be tried in the same order they are input, and it will stop to the first provider who doesn't fail.
     *
     *
     * *Doesn't work with async subfeatures.*
     *      <span style="white-space: nowrap">`non-empty`</span>
     */
    fallbackProviders?: string;
    /**
     * Optional : When set to **true** (default), the response is an object of responses with providers names as keys : <br>
     *                   ``` {'google' : { 'status': 'success', ... }, } ``` <br>
     *                 When set to **false** the response structure is a list of response objects : <br>
     *                    ``` [{'status': 'success', 'provider': 'google' ... }, ] ```. <br>
     *
     */
    responseAsDict?: boolean;
    /**
     * Optional : When set to **false** (default) the structure of the extracted items is list of objects having different attributes : <br>
     *      ```{'items': [{'attribute_1': 'x1','attribute_2': 'y2'}, ... ]}``` <br>
     *      When it is set to **true**, the response contains an object with each attribute as a list : <br>
     *      ```{ 'attribute_1': ['x1','x2', ...], 'attribute_2': [y1, y2, ...]}```
     */
    attributesAsList?: boolean;
    /**
     * Optional : Shows the original response of the provider.<br>
     *         When set to **true**, a new attribute *original_response* will appear in the response object.
     */
    showOriginalResponse?: boolean;
    /**
     * A dictionnary or a json object to specify specific models to use for some providers. <br>                     It can be in the following format: {'google' : 'google_model', ibm': 'ibm_model'...}.
     *                      **Caution**: setting models can be done only with `Content-Type` : `application/json`.
     *
     */
    settings?: Record<string, string | undefined>;
    /** Text to analyze <span style="white-space: nowrap">`non-empty`</span> */
    text: string;
    /** Language code expected (ex: en, fr) */
    language?: string;
    option?: EdenAi.AudiotextToSpeechTextToSpeechRequestOption;
    /** Increase or decrease the speaking rate by expressing a positif or negatif number ranging between             100 and -100 (a relative value as percentage varying from -100% to 100%) */
    rate?: number;
    /** Increase or decrease the speaking pitch by expressing a positif or negatif number ranging between             100 and -100 (a relative value as percentage varying from -100% to 100%) */
    pitch?: number;
    /** Increase or decrease the audio volume by expressing a positif or negatif number ranging between             100 and -100 (a relative value as percentage varying from -100% to 100%) */
    volume?: number;
    /** Optional parameter to specify the audio format in which the audio will be generated. By default,             audios are encoded in MP3, except for lovoai which use the wav container. */
    audioFormat?: string;
    /** Optional. The synthesis sample rate (in hertz) for this audio. When this is specified, the audio will be converted             either to the right passed value, or to a the nearest value acceptable by the provider */
    samplingRate?: number;
}
